# Proxmox VE 7.1 NAS and Gaming VMs - 03 - Proxmox Tweaks

## Table of Contents:
> **Hint:** Github has a drop-down automatic TOC, find the **â‰¡** icon on the top-left

* ^ [Introduction](00.Introduction.md)  (*links to* ***other pages***)
* > 03 - Proxmox Tweaks (***this page***)
    + [03.A. UI Adjustments](#03a-ui-adjustments)
    + [03.B. System Setup](#03b-system-setup)
        - [03.B.i Free/non-Subscription Repo](#03bi-freenon-subscription-repo)
        - [03.B.ii System Update](#03bii-system-update)
    + [03.C Importing Existing ZFS Pool](#03c-importing-existing-zfs-pool)
    + [03.D. Minimizing SSD Wear](#03c-minimizing-ssd-wear)


---

## 03.A. UI Adjustments

**NOTES:**

*These are* ***entirely optional*** and modify system files in a way that can be overridden in Proxmox updates. 
    + In which case you may need to re-apply them (I had to do just that after my first system update).
    + To be 100% safe you can revert these prior to applying updates but that shouldn't be needed. 
* I just do these first thing as it makes doing the rest of the admin tasks a bit nicer for me. 

* *Dark Mode*
    + There isn't an official way to get Dark Mode on your Proxmox UI
    + [PVEDiscordDark](https://github.com/Weilbyte/PVEDiscordDark) works very well and can be easily uninstalled if you don't like it. Use the instructions there, including a shift+reload in your browser, and come back here. 

* *Remove the "No Subscription" popups*
    + Honestly these are pretty mild popups, but just like Dark Mode, you likely already know you don't have a subscription and if you're using this guide you likely won't be getting one (though it's really nice to me to know I can in the future if needed). 
    + [Use Dannyda's script](https://dannyda.com/2020/05/17/how-to-remove-you-do-not-have-a-valid-subscription-for-this-server-from-proxmox-virtual-environment-6-1-2-proxmox-ve-6-1-2-pve-6-1-2/)
        - There are multiple versions listed, use the one for 7.1 (the last one, in chronological order)
        - This creates a backup of the original file. To revert the change just do this: `mv /usr/share/javascript/proxmox-widget-toolkit/proxmoxlib.js.backup /usr/share/javascript/proxmox-widget-toolkit/proxmoxlib.js && systemctl restart pveproxy.service` (shift+reload your browser to load the change)
    + ~~Follow the instructions on [John's Computer Services](https://johnscs.com/remove-proxmox51-subscription-notice/).~~  ... for now don't use this one as it blocks some UI elements. I've reported the problem to him. 
    + Alternately if you want to keep this change active through updates, I found [PVE Nag Buster](https://github.com/foundObjects/pve-nag-buster/) from this [Reddit thread](https://www.reddit.com/r/Proxmox/comments/tgojp1/removing_proxmox_subscription_notice/). I've chosen to use the simple edit from Dannyda above for now as I don't want the additional package installed. Your choice may vary. 

---

## 03.B. System Setup

These are ***recommended*** changes and some may be critical. 

### 03.B.i Free/non-Subscription Repo

* Navigate to 'Datacenter' > [your Proxmox host name] > 'Updates' > 'Repositories'
    + **No need to do this if you DO have a subscription. But for the home user this is needed to get updates running.** 
    + click the 'Add' button and add the "No-Subscription" repo
    + click the line for "https://enterprise.proxmox.com/debian/pve" (components has "pve-enterprise") and then click the 'Disable' button

---

### 03.B.ii System Update

* 'Datacenter' > [your machine] > 'Updates'
    + 'Refresh' (and click the top-right 'X' when you see "TASK OK")
    + '>_ Upgrade'
        - opens a window with a shell
        - if all looks good, hit [enter] to accept the 'Y/n' prompt
        - let it run
            * it's done when you see the shell prompt return
            * look to see if the last message recommends a reboot
            * close the shell window
        - if it recommended reboot, do so (shutdown VMs/etc if running) with the 'Reboot' button in the UI
        - if this included a kernel update
            * you will see multiple kernels to select on boot
            * default is going to be the kernel you just installed

## 03.C. Importing Existing ZFS Pool

**Skip this if you don't have any ZFS pools from previous systems**

I created a ZFS striped pool with my 2 4TB "scratch" disks on a previous system that has data I want to access now (it has my .iso files and support utilities). It's very easy to import this existing pool into Proxmox. As long as you remember the name of the pool. If you don't, the following won't help you figure it out but you should be able to search for that information. 

* Open a root shell 
    + if you have a way to SSH from a terminal, do that via `ssh root@[yourhostip]` ... switching views in the Proxmox UI shell will keep closing the shell
    + if you don't, then you can use the web shell, just make sure you're done with what you're working on before clicking out of it each time (or open a new tab just for the shell)
* `zpool import [poolname]`
    + ie, in my case the pool name is 'xfer', so the command would be `zpool import xfer`
    + if this command complains that the pool was in use before (mine was created on a TrueNAS machine), add -f like: `zpool import -f xfer`
* At this point the pool should be mounted at the filesystem root (ie, "/xfer") and visible in the Proxmox UI. I am not doing any configuration of the mount point or parameters as this is just being used to access files temporarily until I can move them to their final resting place. 

---

## 03.D. Minimizing SSD Wear

Proxmox is built with the assumption of enterprise-class hardware. That doesn't mean it won't work just fine for a consumer-class PC in a home environment. But it does mean that Proxmox has a history of putting heavy usage on it's boot drive. If your boot drive is a consumer SSD and you don't modify things it can wear that device out very quickly (months from 0% to 100% wear). 

This is made worse by the fact that consumer devices vary widely from use of SLC (rare these days, but expected in enterprise SSDs), MLC, TLC, QLC, PLC, etc flash ram. A SLC drive only writes 1 bit per cell, MLC does 2, TLC 3, QLC 4, PLC 5. This increases the amount of storage per cell but each increase lowers the overall lifetime of that cell. [More information on this](https://www.howtogeek.com/444787/multi-layer-ssds-what-are-slc-mlc-tlc-qlc-and-mlc/). 

TLDR; A general rule is ... the cheaper the drive is per TB, the less it can endure writing data. And Proxmox can write a lot of data. 

### Disable Proxmox High Availability Services

**This is only for a single-node Proxmox install (ie, you're not clustering multiple devices that run Proxmox).** However you should be able to enable these services later on if you decide to use clustering. These services do a lot of constant writes. Hopefully future versions of Proxmox will look at giving a UI option to write more of this data to RAM, but since we don't *need* them for this type of install, they're going to be turned off. 

```
systemctl disable pve-ha-lrm
systemctl disable pve-ha-crm
systemctl disable corosync.service
systemctl disable pvesr.timer
```

**NOTES:**

* `systemctl disable pvesr.timer` gave an error, likely as I had never configured Replication, so don't worry about the message. 
* If you wanted to keep clustering services active but minimize SSD wear, you could look into moving /var/lib/pve-cluster into log2ram. [Information about this](https://forum.proxmox.com/threads/proxmox-usb-bootstick-mit-log2ram-oder-folder2ram.76583/) (in German but Google Translate does a good job). I've included what I did for this in the information below.  

### log2ram - Move Frequently Written Files to RAM

[log2ram](https://github.com/azlux/log2ram) creates a ramdisk and mounts it at '/var/log', then will perform a copy daily of the data to a specified drive. If the system is gracefully shudown it will also copy the log to disk.

* Pro: saves the constant writing to log files during normal operation
* Con: **an ungraceful shutdown, including a kernel panic, won't flush the log to disk*

So decide which is more important to you. You can read more about it [here](https://linuxfun.org/en/2021/01/01/what-log2ram-does-en/)

Click the links above to read more about the process and install. My steps are just going to be what I ran to implement the install from the readme (since I log in as root, the `sudo` in the readme version is removed)

**NOTES:** 

* The README for log2ram mentions a config option for 'RSYNC', this is an older version option. Current version of log2ram will just use rsync if it is available, which it is by default on Proxmox VE. I've filed and issue for the maintainer to look at the README contents. 
* The config talks about ZRAM / ZL2R ... this appears to be for raspberry pi systems and I haven't used it. 

```
echo "deb [signed-by=/usr/share/keyrings/azlux-archive-keyring.gpg] http://packages.azlux.fr/debian/ bullseye main" | tee /etc/apt/sources.list.d/azlux.list
wget -O /usr/share/keyrings/azlux-archive-keyring.gpg  https://azlux.fr/repo.gpg
apt update
apt install log2ram
```

At this point if you only want to have the logs in RAM, you can reboot and call this one done. But read the next note before rebooting. 

On reading [this thread](https://forum.proxmox.com/threads/proxmox-usb-bootstick-mit-log2ram-oder-folder2ram.76583/) (German, use translate as necessary) and comparing 'log2ram' vs 'folder2ram' I decided 2 things:

1. I wanted to move additional folders to ram
2. I preferred the script used by 'log2ram' over 'folder2ram'

The folders I wanted to move to RAM (in addition to /var/log):

* 'tmpfs /var/lib/pve-cluster' ... Proxmox clustering info, frequently written (if the service is running)
* 'tmpfs /var/lib/rrdcached' ... Proxmox uses this for the graphs in the UI (and possibly other places), frequently written

The folders I decided NOT to move to RAM for now but that might save more writes:

* '/var/tmp' ... at least some chance that this messes with shared storage (second page of the linked forum post)
* '/var/cache' ... would likely be fine but it has the chance to get VERY big

Configuring 'log2ram' for this is very easy. Edit the file '/etc/log2ram.conf'. When you edit it you can read the comments to get a better idea of what is going on. 

**'/etc/log2ram.conf' parameters changed:**

* from 'SIZE=40M' to 'SIZE=400M'
    + yes, I gave it 400M of space for these files even though at least initially they are nowhere near that large.
    + Remember that I'm running 128GB of RAM, so that's 0.3% of the total. 
    + Put this value at what you feel comfortable with on *your* system. 
* from 'PATH_DISK="/var/log"' to 'PATH_DISK="/var/log;/var/lib/pve-cluster;/var/lib/rrdcached"'
* from 'LOG_DISK_SIZE=100M' to 'LOG_DISK_SIZE=1000M'
    + I'm not 100% sure this needed to be done, have filed a question against it, will update depending on what I hear back. 

Reboot now to have the changes adopted.

What will change on your system:

* The following directories will be renamed:
    + '/var/log' > '/var/hdd.log'
    + '/var/lib/pve-cluster' > '/var/lib/hdd.pve-cluster'
    + '/var/lib/rrdcached' > '/var/lib/hdd.rrdcached'
* The following will be mounted to tmpfs:
    + '/var/log'
    + '/var/lib/pve-cluster'
    + '/var/lib/rrdcached'
* On boot log2ram will rsync from the renamed 'hdd.' versions into RAM
* On sync (which happens automatically on shutdown/reboot) log2ram will rsync the RAM contents to the 'hdd.' directories






---

---

---

### Useful Utilities

* `iotop`
  + to see what is actively using system IO
  + `apt install iotop`


* 
    + 
        - 
            * 

---
> [^ [TOP OF PAGE](#proxmox-ve-71-nas-and-gaming-vms---03---proxmox-tweaks)] ... ***End:*** *Proxmox VE 7.1 NAS and Gaming VMs - Proxmox Tweaks*
> 
> \> NEXT: [04 - Replace Me](03.ReplaceMe.md)
>
> \< PREV: [02 - ProxmoxInstall](02.ProxmoxInstall.md)
Other stuff: Windows on USB for firmware/benchmarks/etc
