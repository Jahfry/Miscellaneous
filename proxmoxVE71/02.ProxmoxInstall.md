# Proxmox VE 7.1 NAS and Gaming VMs - 02 - Proxmox Install

Reminder: I'm a Proxmox newb, so don't take anything here as strict or necessarily even correct. 

*If you already know how you want to do your initial install, feel free to head to [03 - Proxmox Tweaks](03.ProxmoxTweaks.md).*

## Table of Contents:
> **Hint:** Github has a drop-down automatic TOC, find the **â‰¡** icon on the top-left

* ^ [README](README.md)  (*links to* ***other pages***)
* 02 - Proxmox Install (***this page***)
	* [02.A. ISO Image](#02a-iso-image)
	* [02.B. BIOS Settings](#02b-bios-settings)
    + [02.C. Proxmox Install](#02c-install)
* \> [03 - Proxmox Tweaks](03.ProxmoxTweaks.md)  (*next page*)

---

## 02.A. ISO Image

* Download the [Proxmox Install .ISO](https://www.proxmox.com/en/downloads/category/iso-images-pve)
* Burn to a USB drive
* Insert the USB drive into the server

## 02.B. BIOS Settings

*Non-Gigabyte brands may use different wording ("SVM Mode" might be "AMD-V", etc).*

* Boot the server (with the USB drive inserted)
* Press {DEL} key on the BIOS splash screen
* *If you're in 'Easy Mode', switch to 'Advanced' with [F2]*
	+ {F2} toggles between Easy and Advanced
	+ I'm only covering what needs to change from my **default settings** for basic install (ie, PBO, curves, Pstates, etc are up to you)
* 'Tweaker'
	+ **'Advanced CPU Settings' > 'SVM Mode' (Virtualization) = "Enabled"**
* 'Settings'
	* ***Optional:*** 'AMD CPU fTPM' = "Disabled"
		- This enables CPU TPM (Trusted Platform Module)
		- Up through recent BIOS versions this was default "Disabled"
		- Changed to "Enabled" to allow Windows 11 (on bare metal)
		- You can decide if you want it ot not, I just don't need it
	+ *If you BIOS config on a GPU in the second PCI slot*  
	   **'Initial Display Output' = "PCIe S2 Slot"**  
	   *I use this GPU for video display with virtual terminal (kernel cmdline 'fbcon=map:1') so it can be seen while the main VM is in use
	+ *Only* ***if you have ECC memory***:  
	  'Settings' > 'AMD CBS' > 'UMC Common Options' > 'DDR4 Common Options' > 'Common RAS' > 'ECC Configuration' >  
	  **'DRAM ECC Enable' = "True"**
* 'Boot'
	+ **'CSM Support' = "Disabled"**
	    + If input is now delayed/slow, press {Control} + {Alt} + {F6} to use a lower resolution
	    + It will be blurrier but much more responsive
	+ **'Boot Option #1' =** ***{select bootable USB with the Proxmox Install .ISO}***
* 'Save & Exit'
	* *Recommended:* "Save Profiles" ... create a new profile
	* **"Save & Exit Setup"** (system will reboot)


## 02.C. Proxmox Install

* Boot the using the USB
* 'Install Proxmox VE'
* Agree to the license
* **DON'T just click "Next" on the following screen**
	* * ***Decide where to install:** 
	    - *If you only have 1 disk*, you probably already have one in mind
	    - 2 disks, use *ZFS RAID1* (not ZFS RAIDZ ... there are performance issues with using RAIDZ on the boot drive related to efficient VM storage)
	    - 3 disks ... weird choice ... just don't use RAIDZ
	    - 4 disks, use ZFS RAID1+0 (not RAIDZ or RAIDZ2) for redundancy + performance
	    - (etc, if you have multiple disks you probably know how you want to configure)
	+ If you are building a new system, **consider Enterprise-class SSDs with higher write endurance** (lightly used from Ebay can work). I already had the components mentioned below and can't afford more right now. 
    + *My system:*
        - 1 x 465GiB consumer SSD, *this is what I use for root*
            * /dev/sdb
            * What about that SSD wear and tear?
                + Next page ('Proxmox Tweaks') minimizes system writes
                + Small enough I can afford to do backups of it in case of failure
        - 4 x 8TB spinning NAS drives, *reserved for NAS array*
        - 2 x 4TB spinning consumer drives, *could use in a mirror for root to avoid SSD wear but I like keeping these open for other stuff*
        - 2 x 1TB consumer SSDs, *for containers or maybe ZFS L2ARC*
        - 1  x 1TB consumer gen3 NVME, *reserved for games/editing VM*
* *Optional:* Preparing the SSD ... If this is a completely new SSD, or you've already done a wipe on it, you shouldn't need this
    + My small root SSD had a past ZFS root from TrueNAS that caused install to fail with: *'hardisk /dev/sdb too small: 0GB' and the installer failed.* 
	+ If you get this error during install you'll need to reboot
	+ To **avoid** the error, do the following before clicking "Next" ... these 2 commands are redundant, I've used both, you can just use the first unless it fails
        - ***Warning:*** either command will wipe all data on the disk ... be 100% certain you know the device name of the SSD to wipe ('/dev/sdb' in my system)
        - Press {Control} + {Alt} + {F3} to get a Virtual Terminal shell and:  
	        `wipefs -a /dev/sdb`  
	        ***or***  
	        `blkdiscard /dev/sdb`
        - {Control} + {Alt} + {F4} to return to the installer GUI and continue
* **Decide which filesystem to install on** ... if unsure, pick based on your knowledge/comfort
	* *This is just for your root disk, other disks can mix various options*
	+ *I use ZFS RAID0* 
         - Only 1 drive to the boot drive means only RAID0 is a valid pick
         - There are [many other levels that you can use for your boot setup](https://pve.proxmox.com/wiki/ZFS_on_Linux#_installation_as_root_file_system)  multiple disks for the root
    * ***Options:***
	    - **ext4** ... old school, stable, journaling file system
	        * based on ext3 with journaling added on top, so it has decades of use but also hasn't changed much
	    + **xfs** ... newer but not new, journaling file system with extra features over ext4
	        - built from the beginning to have journaling (vs ext4) and be more minimal on system uses than other options mentioned here 
	        - I've successfully used XFS on a large Unraid server and had no complaints.
	    + **zfs** ... newer (to Linux) copy-on-write volume manager
	        - While ZFS on Linux is relatively new, it is a very mature file system having started in the 90s
	        - Can be intimading to new users for how many options it has as well as old Linux users due to ZFS having a lot of knew concepts and things to keep in mind
	        - OpenZFS has become much more stable on Linux in recent years and has very good community resources now
	    + **btrfs** ... Linux-native copy-on-write filesystem
	        - First mainstream copy-on-write file system for Linux. A few years back it had some serious problems but has become much more reliable
	        - It has some benefits of ZFS (which inspired btrfs) but is simpler
	        - Missing many options/tools vs ZFS
* (in Proxmox Install UI) 'Target Harddisk' = {select the correct drive, 'dev/sdb' for me}
* click 'Options' ... instructions based on using ZFS RAID0, if you are doing something else, *modify below*
    + 'Filesystem' = change "ext4" to "zfs (RAID0)"
    + The installer will now show you ALL drives as RAID0 can stripe across multiple disks, **this is not what you want if you have many disks**
        - press button: 'Deselect All'
        - 'Harddisk 0' = {the drive you want to use, '/dev/sdb' for me) ... *other 'Harddisk #' rows empty*
        - tab: 'Advanced Options' 
            * 'ashift' = "13"
	            * uses 8192 sector for this SSD, [more details](https://blog.zanshindojo.org/proxmox-zfs-performance/) 
	            * can't be changed later so *verify the value for your specific disk*
            * 'compress' = "on" (default)
            * 'checksum' = "on" (default)
            * 'copies' = "1" (default)
            * 'hdsize' = "465.0" (default, entire disk)
		- press button: 'OK'
	+ click 'Next' (bottom-right)
* *Timezone* ... fill out and 'Next'
* *Password/Email* ... fill out (and remember the password) and 'Next'
* *Management Network Configuration:* 
	* *NOTES:*
	    + My system has 2 ethernet devices (*ignoring WIFI device*)
		    + enp6s0 = 1Gb Intel NIC ... *I select this one for the host*
		    + enp7s0 = 2.5Gb Realtek NIC ... *I use this for a vmbridge later*
	    + You may have static leases set up on your DHCP server
	    + If your DHCP server also provides IPv6, the installer can mix up the auto-detection so make sure these match address type or you may get error: "Gateway is invalid". 
	        - Installer picked IPv4 for Gateway/DNS but filled in IPv6 for 'IP Address' changing 'Management Interface'
	        - If you need to edit it to make things work, make sure to set the right subnet
	+ 'Management Interface:' = {enp6s0 or whatever device on your system}
	+ 'Hostname (FQDN):' = {pick a fully qualified domain name like 'myhost.lan' or leave default}
	+ 'IP Address (CIDR)' = {"192.168.2.1/18" ... change to IP/subnet on your network}
	+ 'Gateway' = {"192.168.1.1" ... change to your Gateway, usually the router}
	+ 'DNS Server' = {"192.168.1.1" ... change to you DNS, usually the router}
	+ click 'Next' (bottom-right)
* Verify config on Summary and press 'Install'
* You can remove the Proxmox install USB *when you see system reboot* ... but should boot to Proxmox host even with USB inserted
* *After the system reboots and displays a login prompt on the Virtual Terminal*:
    + open the web UI via https://{IPaddress}:8006
    + Uses a self-signed SSL certificate, ignore browser warnings
    + login name 'root' and password set during install

---
> [^ [TOP OF PAGE](#proxmox-ve-71-nas-and-gaming-vms---02---proxmox-install)] ... ***End:*** *Proxmox VE 7.1 NAS and Gaming VMs - Proxmox Install*
> 
> \> NEXT: [03 - Proxmox Tweaks](03.ProxmoxTweaks.md)
>
> \< PREV: [01 - Hardware](01.Hardware.md)
